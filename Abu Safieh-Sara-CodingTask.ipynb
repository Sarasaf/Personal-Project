{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saras\\anaconda3\\envs\\tensorflow_2.1\\lib\\site-packages\\ipykernel_launcher.py:6: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import pandas.util.testing as tm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [20.0, 7.0]\n",
    "plt.rcParams.update({'font.size': 22,})\n",
    "\n",
    "sns.set_palette('viridis')\n",
    "sns.set_style('white')\n",
    "sns.set_context('talk', font_scale=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import itertools\n",
    "\n",
    "f = open('train_input.txt') \n",
    "n = sum(1 for line in open('train_input.txt'))\n",
    "lines = f.readlines()\n",
    "for i in range(n):\n",
    "    if len(lines[i].split(','))>97:\n",
    "      print(len(lines[i].split(',')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import genfromtxt\n",
    "\n",
    "my_data = genfromtxt('train_input.txt', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.101578  , 0.10158128, 0.10159617, ..., 0.10140595, 0.10143126,\n",
       "        0.10143126],\n",
       "       [0.10207225, 0.10207225, 0.10207225, ..., 0.10107636, 0.10128722,\n",
       "        0.10128722],\n",
       "       [0.10139155, 0.1015782 , 0.10156178, ..., 0.10085981, 0.10071466,\n",
       "        0.10072376],\n",
       "       ...,\n",
       "       [0.10179205, 0.10179807, 0.1018056 , ..., 0.10155205, 0.10156836,\n",
       "        0.10152483],\n",
       "       [0.1015354 , 0.101559  , 0.10156939, ..., 0.10149787, 0.10143711,\n",
       "        0.1013596 ],\n",
       "       [0.10293761, 0.10287304, 0.1028678 , ..., 0.10088499, 0.10088521,\n",
       "        0.1007228 ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.utils.normalize(\n",
    "    my_data, axis=-1, order=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.DataFrame(my_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfLabels = pd.read_csv(\"train_labels.txt\",delimiter=',', names = {'Class'})\n",
    "dfLabels.to_csv('train_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36000, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class\n",
       "0      0\n",
       "1      0\n",
       "2      1\n",
       "3      0\n",
       "4      1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(dfLabels.shape)\n",
    "dfLabels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [df1, dfLabels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(frames, axis=1, join='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36000, 98)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8666.89</td>\n",
       "      <td>8667.17</td>\n",
       "      <td>8668.44</td>\n",
       "      <td>8669.02</td>\n",
       "      <td>8669.99</td>\n",
       "      <td>8668.19</td>\n",
       "      <td>8666.94</td>\n",
       "      <td>8663.20</td>\n",
       "      <td>8667.55</td>\n",
       "      <td>8667.11</td>\n",
       "      <td>...</td>\n",
       "      <td>8658.02</td>\n",
       "      <td>8658.77</td>\n",
       "      <td>8657.32</td>\n",
       "      <td>8656.90</td>\n",
       "      <td>8656.26</td>\n",
       "      <td>8652.25</td>\n",
       "      <td>8652.21</td>\n",
       "      <td>8654.37</td>\n",
       "      <td>8654.37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7149.99</td>\n",
       "      <td>7149.99</td>\n",
       "      <td>7149.99</td>\n",
       "      <td>7149.98</td>\n",
       "      <td>7149.85</td>\n",
       "      <td>7149.85</td>\n",
       "      <td>7149.85</td>\n",
       "      <td>7140.03</td>\n",
       "      <td>7141.98</td>\n",
       "      <td>7149.93</td>\n",
       "      <td>...</td>\n",
       "      <td>7100.01</td>\n",
       "      <td>7100.01</td>\n",
       "      <td>7100.01</td>\n",
       "      <td>7100.00</td>\n",
       "      <td>7080.18</td>\n",
       "      <td>7080.18</td>\n",
       "      <td>7080.23</td>\n",
       "      <td>7095.00</td>\n",
       "      <td>7095.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4568.59</td>\n",
       "      <td>4577.00</td>\n",
       "      <td>4576.26</td>\n",
       "      <td>4575.08</td>\n",
       "      <td>4577.89</td>\n",
       "      <td>4582.00</td>\n",
       "      <td>4581.92</td>\n",
       "      <td>4583.18</td>\n",
       "      <td>4586.47</td>\n",
       "      <td>4581.76</td>\n",
       "      <td>...</td>\n",
       "      <td>4524.78</td>\n",
       "      <td>4528.17</td>\n",
       "      <td>4530.00</td>\n",
       "      <td>4543.41</td>\n",
       "      <td>4536.01</td>\n",
       "      <td>4543.50</td>\n",
       "      <td>4544.63</td>\n",
       "      <td>4538.09</td>\n",
       "      <td>4538.50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11825.67</td>\n",
       "      <td>11819.08</td>\n",
       "      <td>11822.95</td>\n",
       "      <td>11820.47</td>\n",
       "      <td>11806.75</td>\n",
       "      <td>11793.46</td>\n",
       "      <td>11799.07</td>\n",
       "      <td>11813.74</td>\n",
       "      <td>11816.46</td>\n",
       "      <td>11815.96</td>\n",
       "      <td>...</td>\n",
       "      <td>11752.62</td>\n",
       "      <td>11769.85</td>\n",
       "      <td>11774.65</td>\n",
       "      <td>11773.01</td>\n",
       "      <td>11777.99</td>\n",
       "      <td>11789.87</td>\n",
       "      <td>11788.03</td>\n",
       "      <td>11781.00</td>\n",
       "      <td>11787.04</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6379.00</td>\n",
       "      <td>6379.00</td>\n",
       "      <td>6378.99</td>\n",
       "      <td>6391.99</td>\n",
       "      <td>6391.99</td>\n",
       "      <td>6390.00</td>\n",
       "      <td>6390.00</td>\n",
       "      <td>6389.99</td>\n",
       "      <td>6388.98</td>\n",
       "      <td>6388.98</td>\n",
       "      <td>...</td>\n",
       "      <td>6424.99</td>\n",
       "      <td>6424.99</td>\n",
       "      <td>6424.67</td>\n",
       "      <td>6423.87</td>\n",
       "      <td>6420.97</td>\n",
       "      <td>6419.97</td>\n",
       "      <td>6419.98</td>\n",
       "      <td>6425.88</td>\n",
       "      <td>6425.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0   8666.89   8667.17   8668.44   8669.02   8669.99   8668.19   8666.94   \n",
       "1   7149.99   7149.99   7149.99   7149.98   7149.85   7149.85   7149.85   \n",
       "2   4568.59   4577.00   4576.26   4575.08   4577.89   4582.00   4581.92   \n",
       "3  11825.67  11819.08  11822.95  11820.47  11806.75  11793.46  11799.07   \n",
       "4   6379.00   6379.00   6378.99   6391.99   6391.99   6390.00   6390.00   \n",
       "\n",
       "          7         8         9  ...        88        89        90        91  \\\n",
       "0   8663.20   8667.55   8667.11  ...   8658.02   8658.77   8657.32   8656.90   \n",
       "1   7140.03   7141.98   7149.93  ...   7100.01   7100.01   7100.01   7100.00   \n",
       "2   4583.18   4586.47   4581.76  ...   4524.78   4528.17   4530.00   4543.41   \n",
       "3  11813.74  11816.46  11815.96  ...  11752.62  11769.85  11774.65  11773.01   \n",
       "4   6389.99   6388.98   6388.98  ...   6424.99   6424.99   6424.67   6423.87   \n",
       "\n",
       "         92        93        94        95        96  Class  \n",
       "0   8656.26   8652.25   8652.21   8654.37   8654.37      0  \n",
       "1   7080.18   7080.18   7080.23   7095.00   7095.00      0  \n",
       "2   4536.01   4543.50   4544.63   4538.09   4538.50      1  \n",
       "3  11777.99  11789.87  11788.03  11781.00  11787.04      0  \n",
       "4   6420.97   6419.97   6419.98   6425.88   6425.88      1  \n",
       "\n",
       "[5 rows x 98 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0    22582\n",
      " 1     6795\n",
      "-1     6623\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.Class.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# using seaborns countplot to show distribution of questions in dataset\n",
    "fig, ax = plt.subplots()\n",
    "g = sns.countplot(df.Class, palette='viridis')\n",
    "g.set_xticklabels(['-1', '0','1'])\n",
    "g.set_yticklabels([])\n",
    "\n",
    "# function to show values on bars\n",
    "def show_values_on_bars(axs):\n",
    "    def _show_on_single_plot(ax):        \n",
    "        for p in ax.patches:\n",
    "            _x = p.get_x() + p.get_width() / 2\n",
    "            _y = p.get_y() + p.get_height()\n",
    "            value = '{:.0f}'.format(p.get_height())\n",
    "            ax.text(_x, _y, value, ha=\"center\") \n",
    "\n",
    "    if isinstance(axs, np.ndarray):\n",
    "        for idx, ax in np.ndenumerate(axs):\n",
    "            _show_on_single_plot(ax)\n",
    "    else:\n",
    "        _show_on_single_plot(axs)\n",
    "show_values_on_bars(ax)\n",
    "\n",
    "sns.despine(left=True, bottom=True)\n",
    "plt.xlabel('')\n",
    "plt.ylabel('')\n",
    "plt.title('Distribution of Classes', fontsize=30)\n",
    "plt.tick_params(axis='x', which='major', labelsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().any().sum()>0 #check for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline model and test harness for the glass identification dataset\n",
    "from collections import Counter\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from pandas import read_csv\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for modeling\n",
    "# Separate input features and target\n",
    "y = df.Class\n",
    "X = df.drop('Class', axis=1)\n",
    "\n",
    "# setting up testing and training sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(X, y, model):\n",
    "\t# define evaluation procedure\n",
    "\tcv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "\t# evaluate model\n",
    "\tscores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\treturn scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.631 (0.000)\n"
     ]
    }
   ],
   "source": [
    "# define the reference model\n",
    "model = DummyClassifier(strategy='most_frequent')\n",
    "# evaluate the model\n",
    "scores = evaluate_model(X_train, y_train, model)\n",
    "# summarize performance\n",
    "print('Mean Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5925555555555555"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=10).fit(X_train, y_train)\n",
    "\n",
    "# predict on test set\n",
    "rfc_pred = rfc.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test, rfc_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6006666666666667"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier().fit(X_train, y_train)\n",
    "\n",
    "# predict on test set\n",
    "knn_pred = knn.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test, knn_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.Class\n",
    "X = df.drop('Class', axis=1)\n",
    "\n",
    "# setting up testing and training sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7455</th>\n",
       "      <td>6485.23</td>\n",
       "      <td>6486.01</td>\n",
       "      <td>6500.23</td>\n",
       "      <td>6493.56</td>\n",
       "      <td>6495.58</td>\n",
       "      <td>6493.81</td>\n",
       "      <td>6496.40</td>\n",
       "      <td>6498.18</td>\n",
       "      <td>6497.99</td>\n",
       "      <td>6498.99</td>\n",
       "      <td>...</td>\n",
       "      <td>6524.02</td>\n",
       "      <td>6521.38</td>\n",
       "      <td>6523.49</td>\n",
       "      <td>6519.16</td>\n",
       "      <td>6515.71</td>\n",
       "      <td>6517.86</td>\n",
       "      <td>6516.01</td>\n",
       "      <td>6518.73</td>\n",
       "      <td>6517.05</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25509</th>\n",
       "      <td>10302.47</td>\n",
       "      <td>10311.93</td>\n",
       "      <td>10309.96</td>\n",
       "      <td>10299.57</td>\n",
       "      <td>10304.83</td>\n",
       "      <td>10317.95</td>\n",
       "      <td>10321.82</td>\n",
       "      <td>10327.45</td>\n",
       "      <td>10320.74</td>\n",
       "      <td>10322.65</td>\n",
       "      <td>...</td>\n",
       "      <td>10347.77</td>\n",
       "      <td>10337.82</td>\n",
       "      <td>10335.86</td>\n",
       "      <td>10330.14</td>\n",
       "      <td>10335.33</td>\n",
       "      <td>10345.27</td>\n",
       "      <td>10336.33</td>\n",
       "      <td>10338.48</td>\n",
       "      <td>10330.86</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28119</th>\n",
       "      <td>10300.70</td>\n",
       "      <td>10305.04</td>\n",
       "      <td>10305.74</td>\n",
       "      <td>10287.85</td>\n",
       "      <td>10282.07</td>\n",
       "      <td>10279.40</td>\n",
       "      <td>10279.19</td>\n",
       "      <td>10285.32</td>\n",
       "      <td>10302.12</td>\n",
       "      <td>10300.53</td>\n",
       "      <td>...</td>\n",
       "      <td>10254.26</td>\n",
       "      <td>10257.78</td>\n",
       "      <td>10258.78</td>\n",
       "      <td>10257.33</td>\n",
       "      <td>10258.28</td>\n",
       "      <td>10262.04</td>\n",
       "      <td>10265.61</td>\n",
       "      <td>10265.56</td>\n",
       "      <td>10266.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28231</th>\n",
       "      <td>10615.00</td>\n",
       "      <td>10596.94</td>\n",
       "      <td>10552.39</td>\n",
       "      <td>10522.00</td>\n",
       "      <td>10549.17</td>\n",
       "      <td>10517.04</td>\n",
       "      <td>10513.00</td>\n",
       "      <td>10495.00</td>\n",
       "      <td>10490.04</td>\n",
       "      <td>10464.96</td>\n",
       "      <td>...</td>\n",
       "      <td>10642.51</td>\n",
       "      <td>10664.99</td>\n",
       "      <td>10650.98</td>\n",
       "      <td>10661.05</td>\n",
       "      <td>10663.98</td>\n",
       "      <td>10664.55</td>\n",
       "      <td>10659.78</td>\n",
       "      <td>10655.00</td>\n",
       "      <td>10642.00</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18875</th>\n",
       "      <td>4771.98</td>\n",
       "      <td>4771.97</td>\n",
       "      <td>4762.19</td>\n",
       "      <td>4771.98</td>\n",
       "      <td>4771.98</td>\n",
       "      <td>4771.98</td>\n",
       "      <td>4771.98</td>\n",
       "      <td>4771.99</td>\n",
       "      <td>4772.00</td>\n",
       "      <td>4772.00</td>\n",
       "      <td>...</td>\n",
       "      <td>4776.93</td>\n",
       "      <td>4776.93</td>\n",
       "      <td>4776.93</td>\n",
       "      <td>4774.26</td>\n",
       "      <td>4774.26</td>\n",
       "      <td>4774.26</td>\n",
       "      <td>4776.93</td>\n",
       "      <td>4776.93</td>\n",
       "      <td>4787.97</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "7455    6485.23   6486.01   6500.23   6493.56   6495.58   6493.81   6496.40   \n",
       "25509  10302.47  10311.93  10309.96  10299.57  10304.83  10317.95  10321.82   \n",
       "28119  10300.70  10305.04  10305.74  10287.85  10282.07  10279.40  10279.19   \n",
       "28231  10615.00  10596.94  10552.39  10522.00  10549.17  10517.04  10513.00   \n",
       "18875   4771.98   4771.97   4762.19   4771.98   4771.98   4771.98   4771.98   \n",
       "\n",
       "              7         8         9  ...        88        89        90  \\\n",
       "7455    6498.18   6497.99   6498.99  ...   6524.02   6521.38   6523.49   \n",
       "25509  10327.45  10320.74  10322.65  ...  10347.77  10337.82  10335.86   \n",
       "28119  10285.32  10302.12  10300.53  ...  10254.26  10257.78  10258.78   \n",
       "28231  10495.00  10490.04  10464.96  ...  10642.51  10664.99  10650.98   \n",
       "18875   4771.99   4772.00   4772.00  ...   4776.93   4776.93   4776.93   \n",
       "\n",
       "             91        92        93        94        95        96  Class  \n",
       "7455    6519.16   6515.71   6517.86   6516.01   6518.73   6517.05     -1  \n",
       "25509  10330.14  10335.33  10345.27  10336.33  10338.48  10330.86      0  \n",
       "28119  10257.33  10258.28  10262.04  10265.61  10265.56  10266.00      0  \n",
       "28231  10661.05  10663.98  10664.55  10659.78  10655.00  10642.00     -1  \n",
       "18875   4774.26   4774.26   4774.26   4776.93   4776.93   4787.97     -1  \n",
       "\n",
       "[5 rows x 98 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.concat([X_train, y_train], axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1    17027\n",
       " 1    17027\n",
       " 0    17027\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separate minority and majority classes\n",
    "not_changed = X[X.Class==0]\n",
    "more = X[X.Class==1]\n",
    "less = X[X.Class==(-1)]\n",
    "# upsample minority\n",
    "more_upsampled = resample(more,\n",
    "                          replace=True, # sample with replacement\n",
    "                          n_samples=len(not_changed), # match number in majority class\n",
    "                          random_state=1) # reproducible results\n",
    "\n",
    "less_upsampled = resample(less,\n",
    "                          replace=True, # sample with replacement\n",
    "                          n_samples=len(not_changed), # match number in majority class\n",
    "                          random_state=1) # reproducible results\n",
    "\n",
    "# combine majority and upsampled minority\n",
    "upsampled = pd.concat([not_changed, more_upsampled, less_upsampled])\n",
    "# combine majority and upsampled minority\n",
    "upsampled.Class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = upsampled.Class\n",
    "X_train = upsampled.drop('Class', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4978888888888889"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier().fit(X_train, y_train)\n",
    "\n",
    "# predict on test set\n",
    "knn_pred = knn.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test, knn_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.566"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=10).fit(X_train, y_train)\n",
    "\n",
    "# predict on test set\n",
    "rfc_pred = rfc.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test, rfc_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.333 (0.000)\n"
     ]
    }
   ],
   "source": [
    "# define the reference model\n",
    "model = DummyClassifier(strategy='most_frequent')\n",
    "# evaluate the model\n",
    "scores = evaluate_model(X_train, y_train, model)\n",
    "# summarize performance\n",
    "print('Mean Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saras\\anaconda3\\envs\\tensorflow_2.1\\lib\\site-packages\\imblearn\\utils\\_validation.py:638: FutureWarning: Pass sampling_strategy=minority as keyword args. From version 0.9 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51081, 97) (51081,)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE('minority')\n",
    "X_sm, y_sm = smote.fit_sample(X_train, y_train)\n",
    "print(X_sm.shape, y_sm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5597777777777778"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=10).fit(X_sm, y_sm)\n",
    "\n",
    "# predict on test set\n",
    "rfc_pred = rfc.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test, rfc_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4978888888888889"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier().fit(X_sm, y_sm)\n",
    "\n",
    "# predict on test set\n",
    "knn_pred = knn.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test, knn_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    5100\n",
       " 0    5100\n",
       "-1    4873\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# still using our separated classes fraud and not_fraud from above\n",
    "\n",
    "# downsample majority\n",
    "not_changed_downsampled = resample(not_changed,\n",
    "                                replace = False, # sample without replacement\n",
    "                                n_samples = len(more), # match minority n\n",
    "                                random_state = 27) # reproducible results\n",
    "\n",
    "# combine minority and downsampled majority\n",
    "downsampled = pd.concat([not_changed_downsampled, more, less])\n",
    "\n",
    "# checking counts\n",
    "downsampled.Class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = downsampled.Class\n",
    "X_train = downsampled.drop('Class', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5063333333333333"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier().fit(X_train, y_train)\n",
    "\n",
    "# predict on test set\n",
    "knn_pred = knn.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test, knn_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46155555555555555"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=10).fit(X_train, y_train)\n",
    "\n",
    "# predict on test set\n",
    "rfc_pred = rfc.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test, rfc_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.338 (0.000)\n"
     ]
    }
   ],
   "source": [
    "# define the reference model\n",
    "model = DummyClassifier(strategy='most_frequent')\n",
    "# evaluate the model\n",
    "scores = evaluate_model(X_train, y_train, model)\n",
    "# summarize performance\n",
    "print('Mean Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.Class\n",
    "X = df.drop('Class', axis=1)\n",
    "\n",
    "# setting up testing and training sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7455</th>\n",
       "      <td>6485.23</td>\n",
       "      <td>6486.01</td>\n",
       "      <td>6500.23</td>\n",
       "      <td>6493.56</td>\n",
       "      <td>6495.58</td>\n",
       "      <td>6493.81</td>\n",
       "      <td>6496.40</td>\n",
       "      <td>6498.18</td>\n",
       "      <td>6497.99</td>\n",
       "      <td>6498.99</td>\n",
       "      <td>...</td>\n",
       "      <td>6524.02</td>\n",
       "      <td>6521.38</td>\n",
       "      <td>6523.49</td>\n",
       "      <td>6519.16</td>\n",
       "      <td>6515.71</td>\n",
       "      <td>6517.86</td>\n",
       "      <td>6516.01</td>\n",
       "      <td>6518.73</td>\n",
       "      <td>6517.05</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25509</th>\n",
       "      <td>10302.47</td>\n",
       "      <td>10311.93</td>\n",
       "      <td>10309.96</td>\n",
       "      <td>10299.57</td>\n",
       "      <td>10304.83</td>\n",
       "      <td>10317.95</td>\n",
       "      <td>10321.82</td>\n",
       "      <td>10327.45</td>\n",
       "      <td>10320.74</td>\n",
       "      <td>10322.65</td>\n",
       "      <td>...</td>\n",
       "      <td>10347.77</td>\n",
       "      <td>10337.82</td>\n",
       "      <td>10335.86</td>\n",
       "      <td>10330.14</td>\n",
       "      <td>10335.33</td>\n",
       "      <td>10345.27</td>\n",
       "      <td>10336.33</td>\n",
       "      <td>10338.48</td>\n",
       "      <td>10330.86</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28119</th>\n",
       "      <td>10300.70</td>\n",
       "      <td>10305.04</td>\n",
       "      <td>10305.74</td>\n",
       "      <td>10287.85</td>\n",
       "      <td>10282.07</td>\n",
       "      <td>10279.40</td>\n",
       "      <td>10279.19</td>\n",
       "      <td>10285.32</td>\n",
       "      <td>10302.12</td>\n",
       "      <td>10300.53</td>\n",
       "      <td>...</td>\n",
       "      <td>10254.26</td>\n",
       "      <td>10257.78</td>\n",
       "      <td>10258.78</td>\n",
       "      <td>10257.33</td>\n",
       "      <td>10258.28</td>\n",
       "      <td>10262.04</td>\n",
       "      <td>10265.61</td>\n",
       "      <td>10265.56</td>\n",
       "      <td>10266.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28231</th>\n",
       "      <td>10615.00</td>\n",
       "      <td>10596.94</td>\n",
       "      <td>10552.39</td>\n",
       "      <td>10522.00</td>\n",
       "      <td>10549.17</td>\n",
       "      <td>10517.04</td>\n",
       "      <td>10513.00</td>\n",
       "      <td>10495.00</td>\n",
       "      <td>10490.04</td>\n",
       "      <td>10464.96</td>\n",
       "      <td>...</td>\n",
       "      <td>10642.51</td>\n",
       "      <td>10664.99</td>\n",
       "      <td>10650.98</td>\n",
       "      <td>10661.05</td>\n",
       "      <td>10663.98</td>\n",
       "      <td>10664.55</td>\n",
       "      <td>10659.78</td>\n",
       "      <td>10655.00</td>\n",
       "      <td>10642.00</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18875</th>\n",
       "      <td>4771.98</td>\n",
       "      <td>4771.97</td>\n",
       "      <td>4762.19</td>\n",
       "      <td>4771.98</td>\n",
       "      <td>4771.98</td>\n",
       "      <td>4771.98</td>\n",
       "      <td>4771.98</td>\n",
       "      <td>4771.99</td>\n",
       "      <td>4772.00</td>\n",
       "      <td>4772.00</td>\n",
       "      <td>...</td>\n",
       "      <td>4776.93</td>\n",
       "      <td>4776.93</td>\n",
       "      <td>4776.93</td>\n",
       "      <td>4774.26</td>\n",
       "      <td>4774.26</td>\n",
       "      <td>4774.26</td>\n",
       "      <td>4776.93</td>\n",
       "      <td>4776.93</td>\n",
       "      <td>4787.97</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "7455    6485.23   6486.01   6500.23   6493.56   6495.58   6493.81   6496.40   \n",
       "25509  10302.47  10311.93  10309.96  10299.57  10304.83  10317.95  10321.82   \n",
       "28119  10300.70  10305.04  10305.74  10287.85  10282.07  10279.40  10279.19   \n",
       "28231  10615.00  10596.94  10552.39  10522.00  10549.17  10517.04  10513.00   \n",
       "18875   4771.98   4771.97   4762.19   4771.98   4771.98   4771.98   4771.98   \n",
       "\n",
       "              7         8         9  ...        88        89        90  \\\n",
       "7455    6498.18   6497.99   6498.99  ...   6524.02   6521.38   6523.49   \n",
       "25509  10327.45  10320.74  10322.65  ...  10347.77  10337.82  10335.86   \n",
       "28119  10285.32  10302.12  10300.53  ...  10254.26  10257.78  10258.78   \n",
       "28231  10495.00  10490.04  10464.96  ...  10642.51  10664.99  10650.98   \n",
       "18875   4771.99   4772.00   4772.00  ...   4776.93   4776.93   4776.93   \n",
       "\n",
       "             91        92        93        94        95        96  Class  \n",
       "7455    6519.16   6515.71   6517.86   6516.01   6518.73   6517.05     -1  \n",
       "25509  10330.14  10335.33  10345.27  10336.33  10338.48  10330.86      0  \n",
       "28119  10257.33  10258.28  10262.04  10265.61  10265.56  10266.00      0  \n",
       "28231  10661.05  10663.98  10664.55  10659.78  10655.00  10642.00     -1  \n",
       "18875   4774.26   4774.26   4774.26   4776.93   4776.93   4787.97     -1  \n",
       "\n",
       "[5 rows x 98 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.concat([X_train, y_train], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1    17027\n",
       " 1    17027\n",
       " 0    17027\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separate minority and majority classes\n",
    "not_changed = X[X.Class==0]\n",
    "more = X[X.Class==1]\n",
    "less = X[X.Class==(-1)]\n",
    "# upsample minority\n",
    "more_upsampled = resample(more,\n",
    "                          replace=True, # sample with replacement\n",
    "                          n_samples=len(not_changed), # match number in majority class\n",
    "                          random_state=100) # reproducible results\n",
    "\n",
    "less_upsampled = resample(less,\n",
    "                          replace=True, # sample with replacement\n",
    "                          n_samples=len(not_changed), # match number in majority class\n",
    "                          random_state=100) # reproducible results\n",
    "\n",
    "# combine majority and upsampled minority\n",
    "upsampled = pd.concat([not_changed, more_upsampled, less_upsampled])\n",
    "# combine majority and upsampled minority\n",
    "upsampled.Class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow.keras\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "y1 = upsampled.Class\n",
    "y2 = y1+1\n",
    "y = to_categorical(y2)\n",
    "\n",
    "X1 = upsampled.drop('Class', axis=1)\n",
    "X = np.array(X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rescaling the data\n",
    "mean = np.mean(X, axis=1, keepdims = True)\n",
    "std = np.std(X, axis=1, keepdims = True)\n",
    "X = (X - mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a utility from sklearn to split and shuffle our dataset.\n",
    "train_df, test_df, train_labels, test_labels = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "import keras\n",
    "\n",
    "def make_model(output_bias=None):\n",
    "  if output_bias is not None:\n",
    "    output_bias = tf.keras.initializers.Constant(output_bias)\n",
    "  model = tensorflow.keras.Sequential([\n",
    "      tensorflow.keras.layers.Dense(\n",
    "          1024, activation='relu',\n",
    "          input_shape=(train_df.shape[-1],)),\n",
    "      tensorflow.keras.layers.Dense(512, activation='relu'),\n",
    "      tensorflow.keras.layers.Dense(256, activation='relu'),\n",
    "      tensorflow.keras.layers.Dropout(0.5),\n",
    "      tensorflow.keras.layers.Dense(128, activation='relu'),\n",
    "      tensorflow.keras.layers.Dense(64, activation='relu'),\n",
    "      tensorflow.keras.layers.Dropout(0.5),\n",
    "      tensorflow.keras.layers.Dense(32, activation='relu'),\n",
    "      tensorflow.keras.layers.Dense(3, activation='softmax',\n",
    "                         bias_initializer=output_bias),\n",
    "  ])\n",
    "\n",
    "  model.compile(\n",
    "    optimizer=tensorflow.keras.optimizers.SGD(learning_rate=0.5),\n",
    "    loss=tensorflow.keras.losses.categorical_crossentropy,\n",
    "    metrics=[tf.keras.metrics.Accuracy()])\n",
    "    \n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_auc', \n",
    "    verbose=1,\n",
    "    patience=10,\n",
    "    mode='max',\n",
    "    restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tensorflow' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-7167a4cf22c4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-28-48c45a33d48e>\u001b[0m in \u001b[0;36mmake_model\u001b[1;34m(output_bias)\u001b[0m\n\u001b[0;32m      5\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0moutput_bias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0moutput_bias\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_bias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m   model = tensorflow.keras.Sequential([\n\u001b[0m\u001b[0;32m      8\u001b[0m       tensorflow.keras.layers.Dense(\n\u001b[0;32m      9\u001b[0m           \u001b[1;36m1024\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tensorflow' is not defined"
     ]
    }
   ],
   "source": [
    "model = make_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-d0fd982abca6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m model.fit(train_df, train_labels,\n\u001b[0m\u001b[0;32m      2\u001b[0m          \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m          \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m          \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m          validation_data=(val_df, val_labels))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.fit(train_df, train_labels,\n",
    "         batch_size=BATCH_SIZE,\n",
    "         epochs=EPOCHS,\n",
    "         verbose=2,\n",
    "         validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_pred = model.predict(val_df)\n",
    "y_val_pred = np.argmax(y_val_pred, axis=1)\n",
    "y_val_test = np.argmax(val_labels, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print(metrics.accuracy_score(y_val_test, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.confusion_matrix(y_val_test, y_val_pred, labels=None, sample_weight=None, normalize=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_df)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "y_test = np.argmax(test_labels, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8228442791426055\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print(metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'metrics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-91970c254d0b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'metrics' is not defined"
     ]
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test, y_pred, labels=None, sample_weight=None, normalize=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"test_input.txt\",delimiter=',', header=None)\n",
    "df.to_csv('test_input.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11341.49</td>\n",
       "      <td>11342.36</td>\n",
       "      <td>11333.20</td>\n",
       "      <td>11340.00</td>\n",
       "      <td>11349.37</td>\n",
       "      <td>11334.93</td>\n",
       "      <td>11352.20</td>\n",
       "      <td>11365.85</td>\n",
       "      <td>11356.80</td>\n",
       "      <td>11360.33</td>\n",
       "      <td>...</td>\n",
       "      <td>11415.53</td>\n",
       "      <td>11421.40</td>\n",
       "      <td>11432.86</td>\n",
       "      <td>11422.43</td>\n",
       "      <td>11437.32</td>\n",
       "      <td>11407.88</td>\n",
       "      <td>11365.64</td>\n",
       "      <td>11366.18</td>\n",
       "      <td>11340.00</td>\n",
       "      <td>11370.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6281.00</td>\n",
       "      <td>6282.99</td>\n",
       "      <td>6282.99</td>\n",
       "      <td>6282.72</td>\n",
       "      <td>6283.04</td>\n",
       "      <td>6287.37</td>\n",
       "      <td>6287.10</td>\n",
       "      <td>6287.13</td>\n",
       "      <td>6291.42</td>\n",
       "      <td>6289.46</td>\n",
       "      <td>...</td>\n",
       "      <td>6273.01</td>\n",
       "      <td>6276.22</td>\n",
       "      <td>6273.48</td>\n",
       "      <td>6277.87</td>\n",
       "      <td>6276.15</td>\n",
       "      <td>6276.89</td>\n",
       "      <td>6282.53</td>\n",
       "      <td>6279.01</td>\n",
       "      <td>6278.84</td>\n",
       "      <td>6278.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8104.65</td>\n",
       "      <td>8104.49</td>\n",
       "      <td>8104.28</td>\n",
       "      <td>8099.99</td>\n",
       "      <td>8098.07</td>\n",
       "      <td>8090.24</td>\n",
       "      <td>8080.00</td>\n",
       "      <td>8087.65</td>\n",
       "      <td>8087.65</td>\n",
       "      <td>8107.59</td>\n",
       "      <td>...</td>\n",
       "      <td>8152.07</td>\n",
       "      <td>8151.48</td>\n",
       "      <td>8149.36</td>\n",
       "      <td>8147.93</td>\n",
       "      <td>8156.03</td>\n",
       "      <td>8157.01</td>\n",
       "      <td>8160.04</td>\n",
       "      <td>8158.04</td>\n",
       "      <td>8164.96</td>\n",
       "      <td>8165.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7269.95</td>\n",
       "      <td>7273.43</td>\n",
       "      <td>7268.77</td>\n",
       "      <td>7273.98</td>\n",
       "      <td>7271.92</td>\n",
       "      <td>7274.08</td>\n",
       "      <td>7279.98</td>\n",
       "      <td>7279.22</td>\n",
       "      <td>7281.78</td>\n",
       "      <td>7282.18</td>\n",
       "      <td>...</td>\n",
       "      <td>7365.76</td>\n",
       "      <td>7370.75</td>\n",
       "      <td>7369.15</td>\n",
       "      <td>7373.47</td>\n",
       "      <td>7371.49</td>\n",
       "      <td>7365.23</td>\n",
       "      <td>7358.29</td>\n",
       "      <td>7360.00</td>\n",
       "      <td>7361.40</td>\n",
       "      <td>7357.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4347.06</td>\n",
       "      <td>4347.06</td>\n",
       "      <td>4347.06</td>\n",
       "      <td>4348.04</td>\n",
       "      <td>4348.04</td>\n",
       "      <td>4348.04</td>\n",
       "      <td>4359.88</td>\n",
       "      <td>4359.88</td>\n",
       "      <td>4359.88</td>\n",
       "      <td>4359.88</td>\n",
       "      <td>...</td>\n",
       "      <td>4342.23</td>\n",
       "      <td>4336.01</td>\n",
       "      <td>4342.23</td>\n",
       "      <td>4342.23</td>\n",
       "      <td>4336.01</td>\n",
       "      <td>4336.01</td>\n",
       "      <td>4336.01</td>\n",
       "      <td>4336.01</td>\n",
       "      <td>4336.01</td>\n",
       "      <td>4348.45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 97 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  11341.49  11342.36  11333.20  11340.00  11349.37  11334.93  11352.20   \n",
       "1   6281.00   6282.99   6282.99   6282.72   6283.04   6287.37   6287.10   \n",
       "2   8104.65   8104.49   8104.28   8099.99   8098.07   8090.24   8080.00   \n",
       "3   7269.95   7273.43   7268.77   7273.98   7271.92   7274.08   7279.98   \n",
       "4   4347.06   4347.06   4347.06   4348.04   4348.04   4348.04   4359.88   \n",
       "\n",
       "         7         8         9   ...        87        88        89        90  \\\n",
       "0  11365.85  11356.80  11360.33  ...  11415.53  11421.40  11432.86  11422.43   \n",
       "1   6287.13   6291.42   6289.46  ...   6273.01   6276.22   6273.48   6277.87   \n",
       "2   8087.65   8087.65   8107.59  ...   8152.07   8151.48   8149.36   8147.93   \n",
       "3   7279.22   7281.78   7282.18  ...   7365.76   7370.75   7369.15   7373.47   \n",
       "4   4359.88   4359.88   4359.88  ...   4342.23   4336.01   4342.23   4342.23   \n",
       "\n",
       "         91        92        93        94        95        96  \n",
       "0  11437.32  11407.88  11365.64  11366.18  11340.00  11370.23  \n",
       "1   6276.15   6276.89   6282.53   6279.01   6278.84   6278.00  \n",
       "2   8156.03   8157.01   8160.04   8158.04   8164.96   8165.01  \n",
       "3   7371.49   7365.23   7358.29   7360.00   7361.40   7357.01  \n",
       "4   4336.01   4336.01   4336.01   4336.01   4336.01   4348.45  \n",
       "\n",
       "[5 rows x 97 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = np.array(df)\n",
    "mean1 = np.mean(X1, axis=1, keepdims = True)\n",
    "std1 = np.std(X1, axis=1, keepdims = True)\n",
    "x_test = (X1 - mean1)/std1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = np.argmax(y_pred1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_labels=y_pred1-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('test_labels.txt', y_pred_labels, delimiter=',', fmt='%i')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
